{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily Traffic Data\n",
    "\n",
    "Data here is sourced from the <a href=\"https://dtdapps.coloradodot.info/otis/TrafficData\">Colorado Dept of Transportation's Online Transportation Information System.</a>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The daily traffic data is returned as an HTML table via the following URL:\n",
    "\n",
    "<blockquote>https://dtdapps.coloradodot.info/otis/TrafficData/GetDailyTrafficVolumeForStationByMonth/{stationID}/true/{year}/{mm}</blockquote>\n",
    "\n",
    "### Where mm is the two-digit month.  Here we loop through all months from 1992 - 2022 for both of the stations we're interested in and parse the HTML tables using BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000126 2022/12\r"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "stationIds = ['000106','000308','000240','000219', '000120', '000236', '000119', '000126']\n",
    "years = range(1992,2023)\n",
    "months = range(1,13)\n",
    "rowList = []\n",
    "errorList = []\n",
    "for year in years:\n",
    "    for month in months:\n",
    "        # Convert month to two-digit equivalent\n",
    "        mm = str(month).zfill(2)\n",
    "        for station in stationIds:\n",
    "            print (f'{station} {year}/{mm}', end='\\r')\n",
    "            url = f'https://dtdapps.coloradodot.info/otis/TrafficData/GetDailyTrafficVolumeForStationByMonth/{station}/true/{year}/{mm}'\n",
    "            r = requests.get(url)\n",
    "            # If the status code isn't 200, something went wrong with the request\n",
    "            if r.status_code != 200:\n",
    "                error = {'error_code': f'HTTP {r.status_code}', 'station_id': station, 'year': year, 'month': mm}\n",
    "                errorList.append(error)\n",
    "            else:\n",
    "                soup = BeautifulSoup(r.text)\n",
    "                # If there are no table details, then there's no data for that particular station/year/month\n",
    "                if len(soup.find_all('td'))==0:\n",
    "                    error = {'error_code': 'No data found', 'station_id':station, 'year':year, 'month':mm}\n",
    "                    errorList.append(error)\n",
    "                else:\n",
    "                    # There's only one table on the page, so we'll take the <tr> tags from that table\n",
    "                    table = soup.find('table').find_all('tr')\n",
    "                    # The headers are in the first row\n",
    "                    headers = [h.text for h in table[0].find_all('th')]\n",
    "                    # For the remaining rows, we extract the text from the <td> tags\n",
    "                    for row in table[1:]:\n",
    "                        r = [val.text for val in row.find_all('td')]\n",
    "                        # Combine the <td> text with the header row to produce a DataFrame row\n",
    "                        r = dict(zip(headers,r))\n",
    "                        # Add the station ID\n",
    "                        r['station_id'] = station\n",
    "                        rowList.append(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table is arranged such that each row is a date and the columns are the traffic counts per hour (labelled as 0h, 1h, 2h ... 23h).  Here we'll reshape the table to a more normalized form and aggregate up to each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rowList)\n",
    "\n",
    "# Convert the hourly column headers to integers\n",
    "# Not used currently, but leaving here in case we decide to go more granular ...\n",
    "# df.columns = [c.replace('h', '') for c in df.columns]\n",
    "\n",
    "# Reshape the data so that each row is an hourly count per station/date\n",
    "df = pd.melt(df, id_vars=['station_id','Count Date','Dir'], var_name='hour', value_name='count')\n",
    "\n",
    "# Convert the integer columns to integers\n",
    "# Not used currently, but leaving here in case we decide to go more granular ...\n",
    "# df['hour'] = df['hour'].astype(int)\n",
    "df['count'] = df['count'].astype(int)\n",
    "df['station_id'] = df['station_id'].astype(int)\n",
    "\n",
    "# Convert the date column to an actual date and rename it to database format\n",
    "df['Count Date'] = pd.to_datetime(df['Count Date'])\n",
    "df.rename({'Count Date':'date', 'Dir':'direction'}, axis=1, inplace=True)\n",
    "\n",
    "# Aggregate the data up to each day\n",
    "df = df.groupby(['station_id','date','direction']).sum()['count'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we translate the primary and secondary direction into compass directions based on which direction the road runs.\n",
    "directions = {236: {'P': 'east', 'S': 'west'},\n",
    "              119: {'P': 'east', 'S': 'west'},\n",
    "              126: {'P': 'east', 'S': 'west'},\n",
    "              106: {'P': 'east', 'S': 'west'},\n",
    "              120: {'P': 'east', 'S': 'west'},\n",
    "              308: {'P': 'north', 'S': 'south'},\n",
    "              240: {'P': 'north', 'S': 'south'},\n",
    "              219: {'P': 'north', 'S': 'south'}             \n",
    "             }\n",
    "# We also add a flag indicating if the direction is headed towards one or more ski resorts or away.  In some cases, both\n",
    "# directions are headed towards.\n",
    "relative_resort_dir = {308: {'north': 'towards', 'south': 'away'},\n",
    "                       240: {'north': 'towards', 'south': 'towards'},\n",
    "                       219: {'north': 'towards', 'south': 'towards'},\n",
    "                       236: {'east': 'towards', 'west': 'away'},\n",
    "                       119: {'east': 'towards', 'west': 'towards'},\n",
    "                       126: {'east': 'towards', 'west': 'away'},\n",
    "                       106: {'east': 'towards', 'west': 'towards'},\n",
    "                       120: {'east': 'away', 'west': 'towards'}                      \n",
    "                      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['direction'] = df.apply(lambda row: directions[row['station_id']][row['direction']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['relative_resort_direction'] = df.apply(lambda row: relative_resort_dir[row['station_id']][row['direction']], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the traffic counts based on population growth in the Denver Metro Area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Population data sourced from <a href=\"https://www.metrodenver.org/regional-data/demographics/population\">here.</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "# Connect to Database\n",
    "import getpass\n",
    "from sqlalchemy.engine.url import URL\n",
    "from sqlalchemy import create_engine\n",
    "%reload_ext sql\n",
    "\n",
    "mypasswd = getpass.getpass()\n",
    "username = 'dgyw5' # Replace with your pawprint\n",
    "host = 'pgsql.dsa.lan'\n",
    "database = 'caponl_22g2'\n",
    "\n",
    "postgres_db = {'drivername': 'postgres',\n",
    "               'username': username,\n",
    "               'password': mypasswd,\n",
    "               'host': host,\n",
    "               'database': database}\n",
    "engine = create_engine(URL(**postgres_db), echo=False)\n",
    "\n",
    "connection_string = f'postgres://{username}:{mypasswd}@{host}/{database}'\n",
    "%sql $connection_string\n",
    "del mypasswd, connection_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgres://dgyw5:***@pgsql.dsa.lan/caponl_22g2\n",
      "1152 rows affected.\n"
     ]
    }
   ],
   "source": [
    "# Load the CO population data\n",
    "co_population_data = %sql select * from co_population_data\n",
    "co_population_data = co_population_data.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add year and month columns to the traffic data to join to the CO population data\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the population data\n",
    "df = df.set_index(['year','month']).join(co_population_data.set_index(['year','month'])).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the adjusted traffic count based on the Denver metro area population growth\n",
    "df['dma_adj_traffic'] = df['count'] / df['dma_pop_frac2020']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns and arrange in logical order\n",
    "df = df[['station_id','date','year','month','direction','relative_resort_direction','count','dma_adj_traffic']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Station data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = pd.DataFrame()\n",
    "for id in df.station_id.unique():\n",
    "    url = f'https://dtdapps.coloradodot.info/otis/API/TRANSYS/GetTrafficStationById/{str(id).zfill(6)}.csv'\n",
    "    r = requests.get(url)\n",
    "    # Parse the csv text into a dataframe\n",
    "    temp = pd.DataFrame([t.split(',') for t in r.text.split('\\r\\n')]) \n",
    "    # column names are in the first row\n",
    "    temp.columns = temp.iloc[0]\n",
    "    # drop the first row\n",
    "    temp = temp.drop(0)\n",
    "    # drop the extraneous blank row\n",
    "    temp = temp.dropna()\n",
    "    # add back to the main dataframe\n",
    "    stations = stations.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename & re-arrange columns\n",
    "colNames = {'STATIONID': 'station_id',\n",
    "            'ROUTE': 'route',\n",
    "            'REFPT': 'begin_ref_point',\n",
    "            'ENDREFPT': 'end_ref_point',\n",
    "            'FIPSCITY': 'city_fips',\n",
    "            'CITY': 'city_name',\n",
    "            'FIPSCOUNTY': 'county_fips',\n",
    "            'COUNTY': 'county_name',\n",
    "            'LOCATION': 'description',\n",
    "            'COUNTSTATIONFACILITY': 'count_station_facility'}\n",
    "\n",
    "stations.rename(colNames, axis=1, inplace=True)\n",
    "\n",
    "stations = stations[colNames.values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data to the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgres://dgyw5:***@pgsql.dsa.lan/caponl_22g2\n",
      "Done.\n",
      "Done.\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "drop table if exists traffic_stations cascade;\n",
    "\n",
    "create table traffic_stations (\n",
    "    station_id int,\n",
    "    route varchar(4),\n",
    "    begin_ref_point float,\n",
    "    end_ref_point float,\n",
    "    city_fips varchar(5),\n",
    "    city_name varchar(25),\n",
    "    county_fips varchar(3),\n",
    "    county_name varchar(15),\n",
    "    description varchar(100),\n",
    "    count_station_facility int,\n",
    "    constraint pk_traffic_stations primary key (station_id)\n",
    ");\n",
    "\n",
    "grant all privileges on traffic_stations to nnfd2, dgyw5, jwcp64, gfdbq;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgres://dgyw5:***@pgsql.dsa.lan/caponl_22g2\n",
      "Done.\n",
      "Done.\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "\n",
    "drop table if exists daily_traffic_data cascade;\n",
    "\n",
    "create table daily_traffic_data (\n",
    "    station_id int,\n",
    "    date date,\n",
    "    year int,\n",
    "    month int,\n",
    "    direction varchar(20),\n",
    "    relative_resort_direction varchar(20),\n",
    "    count int,\n",
    "    dma_adj_traffic float,\n",
    "    constraint pk_daily_traffic_data primary key (station_id, date, direction),\n",
    "    constraint fk_daily_traffic_data foreign key (station_id) references traffic_stations(station_id)\n",
    ");\n",
    "\n",
    "grant all privileges on daily_traffic_data to nnfd2, dgyw5, jwcp64, gfdbq;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations.to_sql('traffic_stations', con=engine, index=False, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql('daily_traffic_data', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgres://dgyw5:***@pgsql.dsa.lan/caponl_22g2\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>8</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(8,)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql select count(*) from traffic_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgres://dgyw5:***@pgsql.dsa.lan/caponl_22g2\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>130273</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(130273,)]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql select count(*) from daily_traffic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
